{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GkHCXH4yUTDk",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Co-creating music with SymphonyNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n8GTiwfRUXFX",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Install the requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YKEHg0S0UYuB",
    "outputId": "3becc6a9-3f5c-440e-99bd-04c22e35de59",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'SymphonyNet'...\n",
      "remote: Enumerating objects: 93, done.\u001B[K\n",
      "remote: Counting objects: 100% (15/15), done.\u001B[K\n",
      "remote: Compressing objects: 100% (15/15), done.\u001B[K\n",
      "remote: Total 93 (delta 3), reused 9 (delta 0), pack-reused 78\u001B[K\n",
      "Unpacking objects: 100% (93/93), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/symphonynet/SymphonyNet.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UV9mJxXfUeJu",
    "outputId": "9f7df837-38ab-4319-8a13-ce6d6aab0e14",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting torch==1.7.1\n",
      "  Downloading torch-1.7.1-cp38-cp38-manylinux1_x86_64.whl (776.8 MB)\n",
      "\u001B[K     |████████████████████████████████| 776.8 MB 4.8 kB/s \n",
      "\u001B[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch==1.7.1) (1.21.6)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.7.1) (4.4.0)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.13.0+cu116\n",
      "    Uninstalling torch-1.13.0+cu116:\n",
      "      Successfully uninstalled torch-1.13.0+cu116\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.14.0+cu116 requires torch==1.13.0, but you have torch 1.7.1 which is incompatible.\n",
      "torchtext 0.14.0 requires torch==1.13.0, but you have torch 1.7.1 which is incompatible.\n",
      "torchaudio 0.13.0+cu116 requires torch==1.13.0, but you have torch 1.7.1 which is incompatible.\u001B[0m\n",
      "Successfully installed torch-1.7.1\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting fairseq==0.10.2\n",
      "  Downloading fairseq-0.10.2-cp38-cp38-manylinux1_x86_64.whl (1.7 MB)\n",
      "\u001B[K     |████████████████████████████████| 1.7 MB 4.7 MB/s \n",
      "\u001B[?25hRequirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from fairseq==0.10.2) (2022.6.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from fairseq==0.10.2) (4.64.1)\n",
      "Collecting hydra-core\n",
      "  Downloading hydra_core-1.3.1-py3-none-any.whl (154 kB)\n",
      "\u001B[K     |████████████████████████████████| 154 kB 45.1 MB/s \n",
      "\u001B[?25hCollecting sacrebleu>=1.4.12\n",
      "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
      "\u001B[K     |████████████████████████████████| 118 kB 44.9 MB/s \n",
      "\u001B[?25hCollecting dataclasses\n",
      "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: cffi in /usr/local/lib/python3.8/dist-packages (from fairseq==0.10.2) (1.15.1)\n",
      "Requirement already satisfied: cython in /usr/local/lib/python3.8/dist-packages (from fairseq==0.10.2) (0.29.32)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from fairseq==0.10.2) (1.7.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from fairseq==0.10.2) (1.21.6)\n",
      "Collecting colorama\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Collecting portalocker\n",
      "  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from sacrebleu>=1.4.12->fairseq==0.10.2) (4.9.2)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.8/dist-packages (from sacrebleu>=1.4.12->fairseq==0.10.2) (0.8.10)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi->fairseq==0.10.2) (2.21)\n",
      "Collecting antlr4-python3-runtime==4.9.*\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "\u001B[K     |████████████████████████████████| 117 kB 51.2 MB/s \n",
      "\u001B[?25hCollecting omegaconf<2.4,>=2.2\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "\u001B[K     |████████████████████████████████| 79 kB 8.6 MB/s \n",
      "\u001B[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from hydra-core->fairseq==0.10.2) (5.10.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from hydra-core->fairseq==0.10.2) (21.3)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.8/dist-packages (from omegaconf<2.4,>=2.2->hydra-core->fairseq==0.10.2) (6.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources->hydra-core->fairseq==0.10.2) (3.11.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->hydra-core->fairseq==0.10.2) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->fairseq==0.10.2) (4.4.0)\n",
      "Building wheels for collected packages: antlr4-python3-runtime\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144575 sha256=c73edfee934faab684215687509f8528171a6b2ac74ae663ca5fba65280336cf\n",
      "  Stored in directory: /root/.cache/pip/wheels/b1/a3/c2/6df046c09459b73cc9bb6c4401b0be6c47048baf9a1617c485\n",
      "Successfully built antlr4-python3-runtime\n",
      "Installing collected packages: antlr4-python3-runtime, portalocker, omegaconf, colorama, sacrebleu, hydra-core, dataclasses, fairseq\n",
      "Successfully installed antlr4-python3-runtime-4.9.3 colorama-0.4.6 dataclasses-0.6 fairseq-0.10.2 hydra-core-1.3.1 omegaconf-2.3.0 portalocker-2.6.0 sacrebleu-2.3.1\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting tensorboardX\n",
      "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
      "\u001B[K     |████████████████████████████████| 125 kB 5.0 MB/s \n",
      "\u001B[?25hRequirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (3.19.6)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (1.21.6)\n",
      "Installing collected packages: tensorboardX\n",
      "Successfully installed tensorboardX-2.5.1\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (1.15.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: more_itertools in /usr/local/lib/python3.8/dist-packages (9.0.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting p_tqdm\n",
      "  Downloading p_tqdm-1.4.0.tar.gz (5.2 kB)\n",
      "Requirement already satisfied: tqdm>=4.45.0 in /usr/local/lib/python3.8/dist-packages (from p_tqdm) (4.64.1)\n",
      "Collecting pathos>=0.2.5\n",
      "  Downloading pathos-0.3.0-py3-none-any.whl (79 kB)\n",
      "\u001B[K     |████████████████████████████████| 79 kB 4.0 MB/s \n",
      "\u001B[?25hRequirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.8/dist-packages (from p_tqdm) (1.15.0)\n",
      "Collecting multiprocess>=0.70.14\n",
      "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
      "\u001B[K     |████████████████████████████████| 132 kB 10.8 MB/s \n",
      "\u001B[?25hCollecting ppft>=1.7.6.6\n",
      "  Downloading ppft-1.7.6.6-py3-none-any.whl (52 kB)\n",
      "\u001B[K     |████████████████████████████████| 52 kB 1.1 MB/s \n",
      "\u001B[?25hRequirement already satisfied: dill>=0.3.6 in /usr/local/lib/python3.8/dist-packages (from pathos>=0.2.5->p_tqdm) (0.3.6)\n",
      "Collecting pox>=0.3.2\n",
      "  Downloading pox-0.3.2-py3-none-any.whl (29 kB)\n",
      "Building wheels for collected packages: p-tqdm\n",
      "  Building wheel for p-tqdm (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for p-tqdm: filename=p_tqdm-1.4.0-py3-none-any.whl size=5400 sha256=100b8edb133e683afda37c3358c1ed0ef4b881a62b44419ab991f3f939d41356\n",
      "  Stored in directory: /root/.cache/pip/wheels/44/8f/aa/b5a167ff59dc658114901c0fbea4fc95bd646b7d18d1d38444\n",
      "Successfully built p-tqdm\n",
      "Installing collected packages: ppft, pox, multiprocess, pathos, p-tqdm\n",
      "Successfully installed multiprocess-0.70.14 p-tqdm-1.4.0 pathos-0.3.0 pox-0.3.2 ppft-1.7.6.6\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting miditoolkit\n",
      "  Downloading miditoolkit-0.1.16-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from miditoolkit) (1.21.6)\n",
      "Collecting mido>=1.1.16\n",
      "  Downloading mido-1.2.10-py2.py3-none-any.whl (51 kB)\n",
      "\u001B[K     |████████████████████████████████| 51 kB 3.3 MB/s \n",
      "\u001B[?25hInstalling collected packages: mido, miditoolkit\n",
      "Successfully installed miditoolkit-0.1.16 mido-1.2.10\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting chorder\n",
      "  Downloading chorder-0.1.4-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from chorder) (1.21.6)\n",
      "Requirement already satisfied: miditoolkit in /usr/local/lib/python3.8/dist-packages (from chorder) (0.1.16)\n",
      "Requirement already satisfied: mido>=1.1.16 in /usr/local/lib/python3.8/dist-packages (from miditoolkit->chorder) (1.2.10)\n",
      "Installing collected packages: chorder\n",
      "Successfully installed chorder-0.1.4\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (1.7.3)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scipy) (1.21.6)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (3.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.21.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting pytorch-fast-transformers==0.4.0\n",
      "  Downloading pytorch-fast-transformers-0.4.0.tar.gz (93 kB)\n",
      "\u001B[K     |████████████████████████████████| 93 kB 1.6 MB/s \n",
      "\u001B[?25hRequirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from pytorch-fast-transformers==0.4.0) (1.7.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->pytorch-fast-transformers==0.4.0) (4.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch->pytorch-fast-transformers==0.4.0) (1.21.6)\n",
      "Building wheels for collected packages: pytorch-fast-transformers\n",
      "  Building wheel for pytorch-fast-transformers (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for pytorch-fast-transformers: filename=pytorch_fast_transformers-0.4.0-cp38-cp38-linux_x86_64.whl size=14854803 sha256=844c58cd7637a0b517b66528510cf9a108d854a479174892695163a975c61afc\n",
      "  Stored in directory: /root/.cache/pip/wheels/74/26/94/8a87caef9e8a3cf0734e6e5a139565f03eb77e56eb28defe52\n",
      "Successfully built pytorch-fast-transformers\n",
      "Installing collected packages: pytorch-fast-transformers\n",
      "Successfully installed pytorch-fast-transformers-0.4.0\n"
     ]
    }
   ],
   "source": [
    "!cat SymphonyNet/requirements.txt | xargs -n 1 -L 1 pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YKauJ7B33icz",
    "outputId": "79e2b51c-90a2-42cc-851b-741f58def073",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following package was automatically installed and is no longer required:\n",
      "  libnvidia-common-460\n",
      "Use 'sudo apt autoremove' to remove it.\n",
      "The following additional packages will be installed:\n",
      "  cpp-6 fonts-dejavu-core fonts-dejavu-extra g++-6 gcc-6 gcc-6-base\n",
      "  libaccinj64-9.1 libasan3 libatk-wrapper-java libatk-wrapper-java-jni\n",
      "  libcublas9.1 libcudart9.1 libcufft9.1 libcufftw9.1 libcuinj64-9.1\n",
      "  libcupti-doc libcupti9.1 libcurand9.1 libcusolver9.1 libcusparse9.1\n",
      "  libgail-common libgail18 libgcc-6-dev libgtk2.0-0 libgtk2.0-bin\n",
      "  libgtk2.0-common libnppc9.1 libnppial9.1 libnppicc9.1 libnppicom9.1\n",
      "  libnppidei9.1 libnppif9.1 libnppig9.1 libnppim9.1 libnppist9.1 libnppisu9.1\n",
      "  libnppitc9.1 libnpps9.1 libnvblas9.1 libnvgraph9.1 libnvrtc9.1\n",
      "  libnvtoolsext1 libnvvm3 libstdc++-6-dev libthrust-dev libvdpau-dev\n",
      "  libxxf86dga1 nvidia-cuda-doc nvidia-cuda-gdb nvidia-profiler\n",
      "  nvidia-visual-profiler openjdk-8-jre openjdk-8-jre-headless x11-utils\n",
      "Suggested packages:\n",
      "  gcc-6-locales g++-6-multilib gcc-6-doc libstdc++6-6-dbg gcc-6-multilib\n",
      "  libgcc1-dbg libgomp1-dbg libitm1-dbg libatomic1-dbg libasan3-dbg\n",
      "  liblsan0-dbg libtsan0-dbg libubsan0-dbg libcilkrts5-dbg libmpx2-dbg\n",
      "  libquadmath0-dbg gvfs libstdc++-6-doc libvdpau-doc nvidia-driver libnss-mdns\n",
      "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
      "  fonts-wqy-zenhei fonts-indic mesa-utils\n",
      "Recommended packages:\n",
      "  libnvcuvid1\n",
      "The following NEW packages will be installed:\n",
      "  cpp-6 fonts-dejavu-core fonts-dejavu-extra g++-6 gcc-6 gcc-6-base\n",
      "  libaccinj64-9.1 libasan3 libatk-wrapper-java libatk-wrapper-java-jni\n",
      "  libcublas9.1 libcudart9.1 libcufft9.1 libcufftw9.1 libcuinj64-9.1\n",
      "  libcupti-dev libcupti-doc libcupti9.1 libcurand9.1 libcusolver9.1\n",
      "  libcusparse9.1 libgail-common libgail18 libgcc-6-dev libgtk2.0-0\n",
      "  libgtk2.0-bin libgtk2.0-common libnppc9.1 libnppial9.1 libnppicc9.1\n",
      "  libnppicom9.1 libnppidei9.1 libnppif9.1 libnppig9.1 libnppim9.1 libnppist9.1\n",
      "  libnppisu9.1 libnppitc9.1 libnpps9.1 libnvblas9.1 libnvgraph9.1 libnvrtc9.1\n",
      "  libnvtoolsext1 libnvvm3 libstdc++-6-dev libthrust-dev libvdpau-dev\n",
      "  libxxf86dga1 nvidia-cuda-dev nvidia-cuda-doc nvidia-cuda-gdb\n",
      "  nvidia-cuda-toolkit nvidia-profiler nvidia-visual-profiler openjdk-8-jre\n",
      "  openjdk-8-jre-headless x11-utils\n",
      "0 upgraded, 57 newly installed, 0 to remove and 20 not upgraded.\n",
      "Need to get 832 MB of archives.\n",
      "After this operation, 2,003 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxxf86dga1 amd64 2:1.1.4-1 [13.7 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 gcc-6-base amd64 6.5.0-2ubuntu1~18.04 [16.7 kB]\n",
      "Get:3 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 libvdpau-dev amd64 1.3-0ubuntu0~gpu18.04.2 [42.7 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 cpp-6 amd64 6.5.0-2ubuntu1~18.04 [6,396 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-core all 2.37-1 [1,041 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-extra all 2.37-1 [1,953 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libasan3 amd64 6.5.0-2ubuntu1~18.04 [313 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libgcc-6-dev amd64 6.5.0-2ubuntu1~18.04 [2,308 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 gcc-6 amd64 6.5.0-2ubuntu1~18.04 [7,067 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libstdc++-6-dev amd64 6.5.0-2ubuntu1~18.04 [1,437 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 g++-6 amd64 6.5.0-2ubuntu1~18.04 [7,213 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libaccinj64-9.1 amd64 9.1.85-3ubuntu1 [1,748 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11-utils amd64 7.7+3build1 [196 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatk-wrapper-java all 0.33.3-20ubuntu0.1 [34.7 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatk-wrapper-java-jni amd64 0.33.3-20ubuntu0.1 [28.3 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libcublas9.1 amd64 9.1.85-3ubuntu1 [25.0 MB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libcudart9.1 amd64 9.1.85-3ubuntu1 [121 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libcufft9.1 amd64 9.1.85-3ubuntu1 [76.1 MB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libcufftw9.1 amd64 9.1.85-3ubuntu1 [131 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libcuinj64-9.1 amd64 9.1.85-3ubuntu1 [1,878 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libcupti9.1 amd64 9.1.85-3ubuntu1 [1,264 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libcurand9.1 amd64 9.1.85-3ubuntu1 [38.9 MB]\n",
      "Get:23 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libcusolver9.1 amd64 9.1.85-3ubuntu1 [28.2 MB]\n",
      "Get:24 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libcusparse9.1 amd64 9.1.85-3ubuntu1 [25.2 MB]\n",
      "Get:25 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-common all 2.24.32-1ubuntu1 [125 kB]\n",
      "Get:26 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-0 amd64 2.24.32-1ubuntu1 [1,769 kB]\n",
      "Get:27 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgail18 amd64 2.24.32-1ubuntu1 [14.2 kB]\n",
      "Get:28 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgail-common amd64 2.24.32-1ubuntu1 [112 kB]\n",
      "Get:29 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-bin amd64 2.24.32-1ubuntu1 [7,536 B]\n",
      "Get:30 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libnppc9.1 amd64 9.1.85-3ubuntu1 [127 kB]\n",
      "Get:31 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libnppial9.1 amd64 9.1.85-3ubuntu1 [3,169 kB]\n",
      "Get:32 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libnppicc9.1 amd64 9.1.85-3ubuntu1 [1,376 kB]\n",
      "Get:33 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libnppicom9.1 amd64 9.1.85-3ubuntu1 [497 kB]\n",
      "Get:34 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libnppidei9.1 amd64 9.1.85-3ubuntu1 [1,673 kB]\n",
      "Get:35 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libnppif9.1 amd64 9.1.85-3ubuntu1 [20.9 MB]\n",
      "Get:36 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libnppig9.1 amd64 9.1.85-3ubuntu1 [9,960 kB]\n",
      "Get:37 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libnppim9.1 amd64 9.1.85-3ubuntu1 [2,295 kB]\n",
      "Get:38 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libnppist9.1 amd64 9.1.85-3ubuntu1 [4,910 kB]\n",
      "Get:39 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libnppisu9.1 amd64 9.1.85-3ubuntu1 [120 kB]\n",
      "Get:40 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libnppitc9.1 amd64 9.1.85-3ubuntu1 [714 kB]\n",
      "Get:41 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libnpps9.1 amd64 9.1.85-3ubuntu1 [2,568 kB]\n",
      "Get:42 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libnvblas9.1 amd64 9.1.85-3ubuntu1 [132 kB]\n",
      "Get:43 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libnvgraph9.1 amd64 9.1.85-3ubuntu1 [6,252 kB]\n",
      "Get:44 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libnvrtc9.1 amd64 9.1.85-3ubuntu1 [6,309 kB]\n",
      "Get:45 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jre-headless amd64 8u352-ga-1~18.04 [28.3 MB]\n",
      "Get:46 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jre amd64 8u352-ga-1~18.04 [69.9 kB]\n",
      "Get:47 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libcupti-dev amd64 9.1.85-3ubuntu1 [73.9 kB]\n",
      "Get:48 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libcupti-doc all 9.1.85-3ubuntu1 [45.3 kB]\n",
      "Get:49 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libnvtoolsext1 amd64 9.1.85-3ubuntu1 [31.3 kB]\n",
      "Get:50 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libnvvm3 amd64 9.1.85-3ubuntu1 [4,274 kB]\n",
      "Get:51 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 libthrust-dev all 1.9.1~9.1.85-3ubuntu1 [461 kB]\n",
      "Get:52 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 nvidia-cuda-dev amd64 9.1.85-3ubuntu1 [263 MB]\n",
      "Get:53 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 nvidia-cuda-doc all 9.1.85-3ubuntu1 [95.2 MB]\n",
      "Get:54 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 nvidia-cuda-gdb amd64 9.1.85-3ubuntu1 [2,724 kB]\n",
      "Get:55 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 nvidia-profiler amd64 9.1.85-3ubuntu1 [2,672 kB]\n",
      "Get:56 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 nvidia-cuda-toolkit amd64 9.1.85-3ubuntu1 [30.4 MB]\n",
      "Get:57 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 nvidia-visual-profiler amd64 9.1.85-3ubuntu1 [115 MB]\n",
      "Fetched 832 MB in 12s (70.1 MB/s)\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 57.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "dpkg-preconfigure: unable to re-open stdin: \n",
      "Selecting previously unselected package libxxf86dga1:amd64.\n",
      "(Reading database ... 124016 files and directories currently installed.)\n",
      "Preparing to unpack .../00-libxxf86dga1_2%3a1.1.4-1_amd64.deb ...\n",
      "Unpacking libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
      "Selecting previously unselected package gcc-6-base:amd64.\n",
      "Preparing to unpack .../01-gcc-6-base_6.5.0-2ubuntu1~18.04_amd64.deb ...\n",
      "Unpacking gcc-6-base:amd64 (6.5.0-2ubuntu1~18.04) ...\n",
      "Selecting previously unselected package cpp-6.\n",
      "Preparing to unpack .../02-cpp-6_6.5.0-2ubuntu1~18.04_amd64.deb ...\n",
      "Unpacking cpp-6 (6.5.0-2ubuntu1~18.04) ...\n",
      "Selecting previously unselected package fonts-dejavu-core.\n",
      "Preparing to unpack .../03-fonts-dejavu-core_2.37-1_all.deb ...\n",
      "Unpacking fonts-dejavu-core (2.37-1) ...\n",
      "Selecting previously unselected package fonts-dejavu-extra.\n",
      "Preparing to unpack .../04-fonts-dejavu-extra_2.37-1_all.deb ...\n",
      "Unpacking fonts-dejavu-extra (2.37-1) ...\n",
      "Selecting previously unselected package libasan3:amd64.\n",
      "Preparing to unpack .../05-libasan3_6.5.0-2ubuntu1~18.04_amd64.deb ...\n",
      "Unpacking libasan3:amd64 (6.5.0-2ubuntu1~18.04) ...\n",
      "Selecting previously unselected package libgcc-6-dev:amd64.\n",
      "Preparing to unpack .../06-libgcc-6-dev_6.5.0-2ubuntu1~18.04_amd64.deb ...\n",
      "Unpacking libgcc-6-dev:amd64 (6.5.0-2ubuntu1~18.04) ...\n",
      "Selecting previously unselected package gcc-6.\n",
      "Preparing to unpack .../07-gcc-6_6.5.0-2ubuntu1~18.04_amd64.deb ...\n",
      "Unpacking gcc-6 (6.5.0-2ubuntu1~18.04) ...\n",
      "Selecting previously unselected package libstdc++-6-dev:amd64.\n",
      "Preparing to unpack .../08-libstdc++-6-dev_6.5.0-2ubuntu1~18.04_amd64.deb ...\n",
      "Unpacking libstdc++-6-dev:amd64 (6.5.0-2ubuntu1~18.04) ...\n",
      "Selecting previously unselected package g++-6.\n",
      "Preparing to unpack .../09-g++-6_6.5.0-2ubuntu1~18.04_amd64.deb ...\n",
      "Unpacking g++-6 (6.5.0-2ubuntu1~18.04) ...\n",
      "Selecting previously unselected package libaccinj64-9.1:amd64.\n",
      "Preparing to unpack .../10-libaccinj64-9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
      "Unpacking libaccinj64-9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Selecting previously unselected package x11-utils.\n",
      "Preparing to unpack .../11-x11-utils_7.7+3build1_amd64.deb ...\n",
      "Unpacking x11-utils (7.7+3build1) ...\n",
      "Selecting previously unselected package libatk-wrapper-java.\n",
      "Preparing to unpack .../12-libatk-wrapper-java_0.33.3-20ubuntu0.1_all.deb ...\n",
      "Unpacking libatk-wrapper-java (0.33.3-20ubuntu0.1) ...\n",
      "Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n",
      "Preparing to unpack .../13-libatk-wrapper-java-jni_0.33.3-20ubuntu0.1_amd64.deb ...\n",
      "Unpacking libatk-wrapper-java-jni:amd64 (0.33.3-20ubuntu0.1) ...\n",
      "Selecting previously unselected package libcublas9.1:amd64.\n",
      "Preparing to unpack .../14-libcublas9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
      "Unpacking libcublas9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Selecting previously unselected package libcudart9.1:amd64.\n",
      "Preparing to unpack .../15-libcudart9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
      "Unpacking libcudart9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Selecting previously unselected package libcufft9.1:amd64.\n",
      "Preparing to unpack .../16-libcufft9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
      "Unpacking libcufft9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Selecting previously unselected package libcufftw9.1:amd64.\n",
      "Preparing to unpack .../17-libcufftw9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
      "Unpacking libcufftw9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Selecting previously unselected package libcuinj64-9.1:amd64.\n",
      "Preparing to unpack .../18-libcuinj64-9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
      "Unpacking libcuinj64-9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Selecting previously unselected package libcupti9.1:amd64.\n",
      "Preparing to unpack .../19-libcupti9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
      "Unpacking libcupti9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Selecting previously unselected package libcurand9.1:amd64.\n",
      "Preparing to unpack .../20-libcurand9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
      "Unpacking libcurand9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Selecting previously unselected package libcusolver9.1:amd64.\n",
      "Preparing to unpack .../21-libcusolver9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
      "Unpacking libcusolver9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Selecting previously unselected package libcusparse9.1:amd64.\n",
      "Preparing to unpack .../22-libcusparse9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
      "Unpacking libcusparse9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Selecting previously unselected package libgtk2.0-common.\n",
      "Preparing to unpack .../23-libgtk2.0-common_2.24.32-1ubuntu1_all.deb ...\n",
      "Unpacking libgtk2.0-common (2.24.32-1ubuntu1) ...\n",
      "Selecting previously unselected package libgtk2.0-0:amd64.\n",
      "Preparing to unpack .../24-libgtk2.0-0_2.24.32-1ubuntu1_amd64.deb ...\n",
      "Unpacking libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\n",
      "Selecting previously unselected package libgail18:amd64.\n",
      "Preparing to unpack .../25-libgail18_2.24.32-1ubuntu1_amd64.deb ...\n",
      "Unpacking libgail18:amd64 (2.24.32-1ubuntu1) ...\n",
      "Selecting previously unselected package libgail-common:amd64.\n",
      "Preparing to unpack .../26-libgail-common_2.24.32-1ubuntu1_amd64.deb ...\n",
      "Unpacking libgail-common:amd64 (2.24.32-1ubuntu1) ...\n",
      "Selecting previously unselected package libgtk2.0-bin.\n",
      "Preparing to unpack .../27-libgtk2.0-bin_2.24.32-1ubuntu1_amd64.deb ...\n",
      "Unpacking libgtk2.0-bin (2.24.32-1ubuntu1) ...\n",
      "Selecting previously unselected package libnppc9.1:amd64.\n",
      "Preparing to unpack .../28-libnppc9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
      "Unpacking libnppc9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Selecting previously unselected package libnppial9.1:amd64.\n",
      "Preparing to unpack .../29-libnppial9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
      "Unpacking libnppial9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Selecting previously unselected package libnppicc9.1:amd64.\n",
      "Preparing to unpack .../30-libnppicc9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
      "Unpacking libnppicc9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Selecting previously unselected package libnppicom9.1:amd64.\n",
      "Preparing to unpack .../31-libnppicom9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
      "Unpacking libnppicom9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Selecting previously unselected package libnppidei9.1:amd64.\n",
      "Preparing to unpack .../32-libnppidei9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
      "Unpacking libnppidei9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Selecting previously unselected package libnppif9.1:amd64.\n",
      "Preparing to unpack .../33-libnppif9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
      "Unpacking libnppif9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Selecting previously unselected package libnppig9.1:amd64.\n",
      "Preparing to unpack .../34-libnppig9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
      "Unpacking libnppig9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Selecting previously unselected package libnppim9.1:amd64.\n",
      "Preparing to unpack .../35-libnppim9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
      "Unpacking libnppim9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Selecting previously unselected package libnppist9.1:amd64.\n",
      "Preparing to unpack .../36-libnppist9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
      "Unpacking libnppist9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Selecting previously unselected package libnppisu9.1:amd64.\n",
      "Preparing to unpack .../37-libnppisu9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
      "Unpacking libnppisu9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Selecting previously unselected package libnppitc9.1:amd64.\n",
      "Preparing to unpack .../38-libnppitc9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
      "Unpacking libnppitc9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Selecting previously unselected package libnpps9.1:amd64.\n",
      "Preparing to unpack .../39-libnpps9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
      "Unpacking libnpps9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Selecting previously unselected package libnvblas9.1:amd64.\n",
      "Preparing to unpack .../40-libnvblas9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
      "Unpacking libnvblas9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Selecting previously unselected package libnvgraph9.1:amd64.\n",
      "Preparing to unpack .../41-libnvgraph9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
      "Unpacking libnvgraph9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Selecting previously unselected package libnvrtc9.1:amd64.\n",
      "Preparing to unpack .../42-libnvrtc9.1_9.1.85-3ubuntu1_amd64.deb ...\n",
      "Unpacking libnvrtc9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Selecting previously unselected package libvdpau-dev:amd64.\n",
      "Preparing to unpack .../43-libvdpau-dev_1.3-0ubuntu0~gpu18.04.2_amd64.deb ...\n",
      "Unpacking libvdpau-dev:amd64 (1.3-0ubuntu0~gpu18.04.2) ...\n",
      "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
      "Preparing to unpack .../44-openjdk-8-jre-headless_8u352-ga-1~18.04_amd64.deb ...\n",
      "Unpacking openjdk-8-jre-headless:amd64 (8u352-ga-1~18.04) ...\n",
      "Selecting previously unselected package openjdk-8-jre:amd64.\n",
      "Preparing to unpack .../45-openjdk-8-jre_8u352-ga-1~18.04_amd64.deb ...\n",
      "Unpacking openjdk-8-jre:amd64 (8u352-ga-1~18.04) ...\n",
      "Selecting previously unselected package libcupti-dev:amd64.\n",
      "Preparing to unpack .../46-libcupti-dev_9.1.85-3ubuntu1_amd64.deb ...\n",
      "Unpacking libcupti-dev:amd64 (9.1.85-3ubuntu1) ...\n",
      "Selecting previously unselected package libcupti-doc.\n",
      "Preparing to unpack .../47-libcupti-doc_9.1.85-3ubuntu1_all.deb ...\n",
      "Unpacking libcupti-doc (9.1.85-3ubuntu1) ...\n",
      "Selecting previously unselected package libnvtoolsext1:amd64.\n",
      "Preparing to unpack .../48-libnvtoolsext1_9.1.85-3ubuntu1_amd64.deb ...\n",
      "Unpacking libnvtoolsext1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Selecting previously unselected package libnvvm3:amd64.\n",
      "Preparing to unpack .../49-libnvvm3_9.1.85-3ubuntu1_amd64.deb ...\n",
      "Unpacking libnvvm3:amd64 (9.1.85-3ubuntu1) ...\n",
      "Selecting previously unselected package libthrust-dev.\n",
      "Preparing to unpack .../50-libthrust-dev_1.9.1~9.1.85-3ubuntu1_all.deb ...\n",
      "Unpacking libthrust-dev (1.9.1~9.1.85-3ubuntu1) ...\n",
      "Selecting previously unselected package nvidia-cuda-dev.\n",
      "Preparing to unpack .../51-nvidia-cuda-dev_9.1.85-3ubuntu1_amd64.deb ...\n",
      "Unpacking nvidia-cuda-dev (9.1.85-3ubuntu1) ...\n",
      "Selecting previously unselected package nvidia-cuda-doc.\n",
      "Preparing to unpack .../52-nvidia-cuda-doc_9.1.85-3ubuntu1_all.deb ...\n",
      "Unpacking nvidia-cuda-doc (9.1.85-3ubuntu1) ...\n",
      "Selecting previously unselected package nvidia-cuda-gdb.\n",
      "Preparing to unpack .../53-nvidia-cuda-gdb_9.1.85-3ubuntu1_amd64.deb ...\n",
      "Unpacking nvidia-cuda-gdb (9.1.85-3ubuntu1) ...\n",
      "Selecting previously unselected package nvidia-profiler.\n",
      "Preparing to unpack .../54-nvidia-profiler_9.1.85-3ubuntu1_amd64.deb ...\n",
      "Unpacking nvidia-profiler (9.1.85-3ubuntu1) ...\n",
      "Selecting previously unselected package nvidia-cuda-toolkit.\n",
      "Preparing to unpack .../55-nvidia-cuda-toolkit_9.1.85-3ubuntu1_amd64.deb ...\n",
      "Unpacking nvidia-cuda-toolkit (9.1.85-3ubuntu1) ...\n",
      "Selecting previously unselected package nvidia-visual-profiler.\n",
      "Preparing to unpack .../56-nvidia-visual-profiler_9.1.85-3ubuntu1_amd64.deb ...\n",
      "Unpacking nvidia-visual-profiler (9.1.85-3ubuntu1) ...\n",
      "Setting up libcufft9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Setting up libnvtoolsext1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Setting up libcusparse9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Setting up libgtk2.0-common (2.24.32-1ubuntu1) ...\n",
      "Setting up nvidia-cuda-doc (9.1.85-3ubuntu1) ...\n",
      "Setting up libthrust-dev (1.9.1~9.1.85-3ubuntu1) ...\n",
      "Setting up libvdpau-dev:amd64 (1.3-0ubuntu0~gpu18.04.2) ...\n",
      "Setting up fonts-dejavu-core (2.37-1) ...\n",
      "Setting up libcupti-doc (9.1.85-3ubuntu1) ...\n",
      "Setting up gcc-6-base:amd64 (6.5.0-2ubuntu1~18.04) ...\n",
      "Setting up libcuinj64-9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Setting up nvidia-cuda-gdb (9.1.85-3ubuntu1) ...\n",
      "Setting up libnppc9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Setting up libaccinj64-9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Setting up libcurand9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Setting up libnvrtc9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Setting up libnppitc9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Setting up libnppif9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Setting up libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
      "Setting up libnvvm3:amd64 (9.1.85-3ubuntu1) ...\n",
      "Setting up libcublas9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Setting up cpp-6 (6.5.0-2ubuntu1~18.04) ...\n",
      "Setting up libcupti9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Setting up libcufftw9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Setting up libcudart9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Setting up libnppim9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Setting up fonts-dejavu-extra (2.37-1) ...\n",
      "Setting up libcusolver9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Setting up libnvblas9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Setting up libnppidei9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Setting up openjdk-8-jre-headless:amd64 (8u352-ga-1~18.04) ...\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
      "Setting up libnppial9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Setting up nvidia-profiler (9.1.85-3ubuntu1) ...\n",
      "Setting up libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\n",
      "Setting up libasan3:amd64 (6.5.0-2ubuntu1~18.04) ...\n",
      "Setting up libgcc-6-dev:amd64 (6.5.0-2ubuntu1~18.04) ...\n",
      "Setting up libstdc++-6-dev:amd64 (6.5.0-2ubuntu1~18.04) ...\n",
      "Setting up libgail18:amd64 (2.24.32-1ubuntu1) ...\n",
      "Setting up libnppicom9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Setting up libnppisu9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Setting up libcupti-dev:amd64 (9.1.85-3ubuntu1) ...\n",
      "Setting up libnpps9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Setting up libnppicc9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Setting up x11-utils (7.7+3build1) ...\n",
      "Setting up libnppist9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Setting up libgail-common:amd64 (2.24.32-1ubuntu1) ...\n",
      "Setting up libnppig9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Setting up libnvgraph9.1:amd64 (9.1.85-3ubuntu1) ...\n",
      "Setting up nvidia-cuda-dev (9.1.85-3ubuntu1) ...\n",
      "Setting up gcc-6 (6.5.0-2ubuntu1~18.04) ...\n",
      "Setting up g++-6 (6.5.0-2ubuntu1~18.04) ...\n",
      "Setting up nvidia-cuda-toolkit (9.1.85-3ubuntu1) ...\n",
      "Setting up libatk-wrapper-java (0.33.3-20ubuntu0.1) ...\n",
      "Setting up libgtk2.0-bin (2.24.32-1ubuntu1) ...\n",
      "Setting up libatk-wrapper-java-jni:amd64 (0.33.3-20ubuntu0.1) ...\n",
      "Setting up openjdk-8-jre:amd64 (8u352-ga-1~18.04) ...\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/policytool to provide /usr/bin/policytool (policytool) in auto mode\n",
      "Setting up nvidia-visual-profiler (9.1.85-3ubuntu1) ...\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1.6) ...\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
      "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
      "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
      "Processing triggers for mime-support (3.60ubuntu1) ...\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get install nvidia-cuda-toolkit nvidia-cuda-dev libcupti-dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HnMEqZtazVdC",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oCxzj8UA0OGZ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "1. Загружаем MIDI в папку data/midis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kowj5Sn231i2",
    "outputId": "0fd5a33f-a924-49a0-eaca-99aeadbf2fe9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/SymphonyNet\n"
     ]
    }
   ],
   "source": [
    "%cd SymphonyNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aC7oO8OozdAE",
    "outputId": "afab127e-bb9c-40ab-f348-ac30dbeb1b2e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "starts processing 4 midis with 32 processes\n",
      "MIDI data preprocessing takes: 5.747195482254028s, 4 samples collected, 0 broken.\n",
      "Create txt file takes:  0.016820192337036133\n"
     ]
    }
   ],
   "source": [
    "!python3 src/preprocess/preprocess_midi.py"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pwd"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vILWIaLr3JYg",
    "outputId": "47fe6456-a19f-46c8-ee92-a518b10f4b9b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/SymphonyNet\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!g++ -std=c++11 -pthread -O3 src/musicBPE/fastBPE/main.cc -IfastBPE -o music_bpe_exec"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "djR9Wc-Z2-8L",
    "outputId": "1cffcf45-af09-4a94-8c9d-2b75319ce218",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "In file included from \u001B[01m\u001B[Ksrc/musicBPE/fastBPE/main.cc:1:0\u001B[m\u001B[K:\n",
      "\u001B[01m\u001B[Ksrc/musicBPE/fastBPE/fastBPE.hpp:\u001B[m\u001B[K In function ‘\u001B[01m\u001B[Kvoid fastBPE::readText(const char*, std::unordered_map<std::__cxx11::basic_string<char>, unsigned int>&)\u001B[m\u001B[K’:\n",
      "\u001B[01m\u001B[Ksrc/musicBPE/fastBPE/fastBPE.hpp:50:11:\u001B[m\u001B[K \u001B[01;35m\u001B[Kwarning: \u001B[m\u001B[Kignoring return value of ‘\u001B[01m\u001B[Kint fscanf(FILE*, const char*, ...)\u001B[m\u001B[K’, declared with attribute warn_unused_result [\u001B[01;35m\u001B[K-Wunused-result\u001B[m\u001B[K]\n",
      "     \u001B[01;35m\u001B[Kfscanf(fin, \"%d\", &tot)\u001B[m\u001B[K;\n",
      "     \u001B[01;35m\u001B[K~~~~~~^~~~~~~~~~~~~~~~~\u001B[m\u001B[K\n",
      "\u001B[01m\u001B[Ksrc/musicBPE/fastBPE/fastBPE.hpp:53:15:\u001B[m\u001B[K \u001B[01;35m\u001B[Kwarning: \u001B[m\u001B[Kignoring return value of ‘\u001B[01m\u001B[Kint fscanf(FILE*, const char*, ...)\u001B[m\u001B[K’, declared with attribute warn_unused_result [\u001B[01;35m\u001B[K-Wunused-result\u001B[m\u001B[K]\n",
      "         \u001B[01;35m\u001B[Kfscanf(fin, \"%s\", cur_word)\u001B[m\u001B[K;\n",
      "         \u001B[01;35m\u001B[K~~~~~~^~~~~~~~~~~~~~~~~~~~~\u001B[m\u001B[K\n",
      "\u001B[01m\u001B[Ksrc/musicBPE/fastBPE/fastBPE.hpp:55:15:\u001B[m\u001B[K \u001B[01;35m\u001B[Kwarning: \u001B[m\u001B[Kignoring return value of ‘\u001B[01m\u001B[Kint fscanf(FILE*, const char*, ...)\u001B[m\u001B[K’, declared with attribute warn_unused_result [\u001B[01;35m\u001B[K-Wunused-result\u001B[m\u001B[K]\n",
      "         \u001B[01;35m\u001B[Kfscanf(fin, \"%d\", &cnt)\u001B[m\u001B[K;\n",
      "         \u001B[01;35m\u001B[K~~~~~~^~~~~~~~~~~~~~~~~\u001B[m\u001B[K\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!python3 src/preprocess/get_bpe_data.py"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yv99GRO_z1zl",
    "outputId": "4797ed9e-d246-445d-8161-3069885595fd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\rreading original txt file...: 0it [00:00, ?it/s]\rreading original txt file...: 4it [00:00, 5785.25it/s]\n",
      "\r  0% 0/4 [00:00<?, ?it/s]\r100% 4/4 [00:00<00:00, 79.91it/s]\n",
      "learnBPE finished, time elapsed:　0.1564497947692871\n",
      "\r  0% 0/597 [00:00<?, ?it/s]\r100% 597/597 [00:00<00:00, 46509.89it/s]\n",
      "average mulpi length original:　2.312249443207127, average mulpi length after bpe: 1.0\n",
      "applyBPE for word finished, time elapsed:　0.020878314971923828\n",
      "\rwriting bpe data:   0% 0/4 [00:00<?, ?it/s]\rwriting bpe data: 100% 4/4 [00:00<00:00, 109.89it/s]\n",
      "applyBPE for corpus finished, time elapsed:　0.03667807579040527\n",
      "before tokens: 26617, after tokens: 23671, delta: 0.1106811436300109\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**В config.sh добавить BPE = 1**"
   ],
   "metadata": {
    "id": "YDpSEX--0A4S",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2DsFWvebzjtN",
    "outputId": "b8c2e650-b4c1-4e47-b007-e9165f282974",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "config.sh: \n",
      "BPE=1\n",
      "IGNORE_META_LOSS=1\n",
      "PI_LEVEL=2\n",
      "RECOVER=0\n",
      "SEED=1998\n",
      "MAX_POS_LEN=4096\n",
      "MAXPIECES=10000000\n",
      "RATIO=4\n",
      "SOR=4\n",
      "TOTAL_UPDATES=210000\n",
      "WARMUP_UPDATES=5000\n",
      "PEAK_LR=0.0003\n",
      "BATCH_SIZE=128\n",
      "MAX_SENTENCES=2\n",
      "\rreading...: 0it [00:00, ?it/s]\rreading...: 4it [00:00, 13888.42it/s]\n",
      "\rsetting up vocabs:   0% 0/4 [00:00<?, ?it/s]\rsetting up vocabs: 100% 4/4 [00:00<00:00, 149.55it/s]\n",
      "max voc idx:  799\n",
      "sub vocab size: 800 36 16 21 \n",
      "total pieces: 4, create dict time: 0.19 s\n",
      "train\n",
      "measure collection finished, total 163 measures, time elapsed: 0.16820025444030762 s\n",
      "max cnt in a sample (rel_pos, measure): 29, 80\n",
      "writing bin file: 100% 2/2 [00:00<00:00, 647.17it/s]\n",
      "write binary finished, write time elapsed 0.00 s\n",
      "valid\n",
      "measure collection finished, total 93 measures, time elapsed: 0.15242314338684082 s\n",
      "max cnt in a sample (rel_pos, measure): 27, 54\n",
      "writing bin file: 100% 1/1 [00:00<00:00, 638.99it/s]\n",
      "write binary finished, write time elapsed 0.00 s\n",
      "test\n",
      "measure collection finished, total 187 measures, time elapsed: 0.1593492031097412 s\n",
      "max cnt in a sample (rel_pos, measure): 35, 114\n",
      "writing bin file: 100% 1/1 [00:00<00:00, 488.68it/s]\n",
      "write binary finished, write time elapsed 0.00 s\n"
     ]
    }
   ],
   "source": [
    "!python3 src/fairseq/make_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sleo5yHgzl2j",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "16c7d499-2c24-4e8d-e9d5-20f81b1d39ff",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2022-12-25 09:46:47 | INFO | fairseq_cli.train | Namespace(adam_betas='(0.9, 0.98)', adam_eps=1e-06, add_bos_token=False, all_gather_list_size=16384, arch='linear_transformer_multi', batch_size=2, batch_size_valid=2, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='_linear_4096_chord_bpe_hardloss1_PI2', clip_norm=0.0, cpu=False, criterion='multiple_loss', curriculum=0, data='data/model_spec/linear_4096_chord_bpe_hardloss1/bin', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.1, dur_voc_size=36, embed_dim=512, empty_cache_freq=0, end_learning_rate=0.0, evt_voc_size=800, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, future_target=False, gen_subset='test', ins_voc_size=21, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, localsgd_frequency=3, log_format='simple', log_interval=100, lr=[0.0003], lr_scheduler='polynomial_decay', max_epoch=5, max_mea_pos=245, max_rel_pos=34, max_target_positions=None, max_tokens=None, max_tokens_valid=None, max_update=210000, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_seed_provided=False, nprocs_per_node=1, num_attention_heads=16, num_layers=12, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', output_dictionary_size=-1, past_target=False, patience=-1, perm_inv=2, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, power=1.0, profile=False, quantization_config_path=None, ratio=4, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='ckpt/checkpoint_last_linear_4096_chord_bpe_hardloss1_PI2.pt', sample_break_mode='complete_doc', sample_overlap_rate=4, save_dir='ckpt/', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1998, self_target=False, sentence_avg=False, shard_id=0, shorten_data_split_list='', shorten_method='none', skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_time_hours=0, task='symphony_modeling', tensorboard_logdir='logs/linear_4096_chord_bpe_hardloss1_PI2', threshold_loss_scale=None, tokenizer=None, tokens_per_sample=4096, total_num_update=210000, tpu=False, train_subset='train', trk_voc_size=16, update_freq=[64], use_bmuf=False, use_old_adam=False, user_dir='src/fairseq/linear_transformer', valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=5000, weight_decay=0.01, zero_sharding='none')\n",
      "2022-12-25 09:46:47 | INFO | fairseq.tasks.language_modeling | dictionary: 800 types\n",
      "2022-12-25 09:46:47 | INFO | fairseq.data.data_utils | loaded 94 examples from: data/model_spec/linear_4096_chord_bpe_hardloss1/bin/valid\n",
      "2022-12-25 09:46:48 | INFO | fairseq_cli.train | LinearTransformerMultiHeadLM(\n",
      "  (decoder): LinearTransformerMultiHeadDecoder(\n",
      "    (wEvte): Embedding(800, 512)\n",
      "    (wTrke): Embedding(16, 512)\n",
      "    (wDure): Embedding(36, 512)\n",
      "    (wRpe): Embedding(35, 512)\n",
      "    (wMpe): Embedding(246, 512)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (ln_f): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "    (model): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (attention): AttentionLayer(\n",
      "            (inner_attention): CausalLinearAttention(\n",
      "              (feature_map): ActivationFunctionFeatureMap()\n",
      "            )\n",
      "            (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (attention): AttentionLayer(\n",
      "            (inner_attention): CausalLinearAttention(\n",
      "              (feature_map): ActivationFunctionFeatureMap()\n",
      "            )\n",
      "            (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): TransformerEncoderLayer(\n",
      "          (attention): AttentionLayer(\n",
      "            (inner_attention): CausalLinearAttention(\n",
      "              (feature_map): ActivationFunctionFeatureMap()\n",
      "            )\n",
      "            (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (3): TransformerEncoderLayer(\n",
      "          (attention): AttentionLayer(\n",
      "            (inner_attention): CausalLinearAttention(\n",
      "              (feature_map): ActivationFunctionFeatureMap()\n",
      "            )\n",
      "            (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (attention): AttentionLayer(\n",
      "            (inner_attention): CausalLinearAttention(\n",
      "              (feature_map): ActivationFunctionFeatureMap()\n",
      "            )\n",
      "            (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (5): TransformerEncoderLayer(\n",
      "          (attention): AttentionLayer(\n",
      "            (inner_attention): CausalLinearAttention(\n",
      "              (feature_map): ActivationFunctionFeatureMap()\n",
      "            )\n",
      "            (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (6): TransformerEncoderLayer(\n",
      "          (attention): AttentionLayer(\n",
      "            (inner_attention): CausalLinearAttention(\n",
      "              (feature_map): ActivationFunctionFeatureMap()\n",
      "            )\n",
      "            (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (7): TransformerEncoderLayer(\n",
      "          (attention): AttentionLayer(\n",
      "            (inner_attention): CausalLinearAttention(\n",
      "              (feature_map): ActivationFunctionFeatureMap()\n",
      "            )\n",
      "            (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (8): TransformerEncoderLayer(\n",
      "          (attention): AttentionLayer(\n",
      "            (inner_attention): CausalLinearAttention(\n",
      "              (feature_map): ActivationFunctionFeatureMap()\n",
      "            )\n",
      "            (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (9): TransformerEncoderLayer(\n",
      "          (attention): AttentionLayer(\n",
      "            (inner_attention): CausalLinearAttention(\n",
      "              (feature_map): ActivationFunctionFeatureMap()\n",
      "            )\n",
      "            (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (10): TransformerEncoderLayer(\n",
      "          (attention): AttentionLayer(\n",
      "            (inner_attention): CausalLinearAttention(\n",
      "              (feature_map): ActivationFunctionFeatureMap()\n",
      "            )\n",
      "            (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (11): TransformerEncoderLayer(\n",
      "          (attention): AttentionLayer(\n",
      "            (inner_attention): CausalLinearAttention(\n",
      "              (feature_map): ActivationFunctionFeatureMap()\n",
      "            )\n",
      "            (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (proj_evt): Linear(in_features=512, out_features=800, bias=False)\n",
      "    (proj_dur): Linear(in_features=512, out_features=36, bias=False)\n",
      "    (proj_trk): Linear(in_features=512, out_features=16, bias=False)\n",
      "    (proj_ins): Linear(in_features=512, out_features=21, bias=False)\n",
      "  )\n",
      ")\n",
      "2022-12-25 09:46:48 | INFO | fairseq_cli.train | task: symphony_modeling (SymphonyModelingTask)\n",
      "2022-12-25 09:46:48 | INFO | fairseq_cli.train | model: linear_transformer_multi (LinearTransformerMultiHeadLM)\n",
      "2022-12-25 09:46:48 | INFO | fairseq_cli.train | criterion: multiple_loss (MultiplelossCriterion)\n",
      "2022-12-25 09:46:48 | INFO | fairseq_cli.train | num. model params: 38857728 (num. trained: 38857728)\n",
      "2022-12-25 09:46:51 | INFO | fairseq.trainer | detected shared parameter: decoder.proj_evt.bias <- decoder.proj_dur.bias\n",
      "2022-12-25 09:46:51 | INFO | fairseq.trainer | detected shared parameter: decoder.proj_evt.bias <- decoder.proj_trk.bias\n",
      "2022-12-25 09:46:51 | INFO | fairseq.trainer | detected shared parameter: decoder.proj_evt.bias <- decoder.proj_ins.bias\n",
      "2022-12-25 09:46:51 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
      "2022-12-25 09:46:51 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 14.756 GB ; name = Tesla T4                                \n",
      "2022-12-25 09:46:51 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
      "2022-12-25 09:46:51 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
      "2022-12-25 09:46:51 | INFO | fairseq_cli.train | max tokens per GPU = None and max sentences per GPU = 2\n",
      "2022-12-25 09:46:51 | INFO | fairseq.trainer | no existing checkpoint found ckpt/checkpoint_last_linear_4096_chord_bpe_hardloss1_PI2.pt\n",
      "2022-12-25 09:46:51 | INFO | fairseq.trainer | loading train data for epoch 1\n",
      "2022-12-25 09:46:51 | INFO | fairseq.data.data_utils | loaded 165 examples from: data/model_spec/linear_4096_chord_bpe_hardloss1/bin/train\n",
      "2022-12-25 09:46:51 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16\n",
      "2022-12-25 09:46:51 | INFO | fairseq.trainer | begin training epoch 1\n",
      "2022-12-25 09:46:58 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "2022-12-25 09:46:59 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.339 | evt_loss 10.289 | dur_loss 2.753 | trk_loss 1.976 | ins_loss 2.339 | ppl 20.24 | evt_ppl 1251.42 | dur_ppl 6.74 | trk_ppl 3.93 | ins_ppl 5.06 | wps 18169.4 | wpb 5317.4 | bsz 1.8 | num_updates 1\n",
      "2022-12-25 09:46:59 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-12-25 09:47:05 | INFO | fairseq.checkpoint_utils | saved checkpoint ckpt/checkpoint1_linear_4096_chord_bpe_hardloss1_PI2.pt (epoch 1 @ 1 updates, score 4.339) (writing took 5.354654082000025 seconds)\n",
      "2022-12-25 09:47:05 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n",
      "2022-12-25 09:47:05 | INFO | train | epoch 001 | loss 4.752 | evt_loss 10.496 | dur_loss 3.25 | trk_loss 2.52 | ins_loss 2.744 | ppl 26.95 | evt_ppl 1443.88 | dur_ppl 9.51 | trk_ppl 5.74 | ins_ppl 6.7 | wps 0 | ups 0 | wpb 29819 | bsz 11 | num_updates 1 | lr 6e-08 | gnorm 6.864 | train_wall 7 | wall 13\n",
      "2022-12-25 09:47:05 | INFO | fairseq.trainer | begin training epoch 2\n",
      "2022-12-25 09:47:08 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "2022-12-25 09:47:09 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.343 | evt_loss 10.299 | dur_loss 2.744 | trk_loss 1.986 | ins_loss 2.344 | ppl 20.29 | evt_ppl 1259.44 | dur_ppl 6.7 | trk_ppl 3.96 | ins_ppl 5.08 | wps 16819.3 | wpb 5289.4 | bsz 1.8 | num_updates 2 | best_loss 4.339\n",
      "2022-12-25 09:47:09 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-12-25 09:47:13 | INFO | fairseq.checkpoint_utils | saved checkpoint ckpt/checkpoint2_linear_4096_chord_bpe_hardloss1_PI2.pt (epoch 2 @ 2 updates, score 4.343) (writing took 3.5624034879999726 seconds)\n",
      "2022-12-25 09:47:13 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)\n",
      "2022-12-25 09:47:13 | INFO | train | epoch 002 | loss 4.73 | evt_loss 10.488 | dur_loss 3.247 | trk_loss 2.452 | ins_loss 2.731 | ppl 26.53 | evt_ppl 1435.8 | dur_ppl 9.5 | trk_ppl 5.47 | ins_ppl 6.64 | wps 2519.9 | ups 0.12 | wpb 21378 | bsz 11 | num_updates 2 | lr 1.2e-07 | gnorm 6.34 | train_wall 3 | wall 22\n",
      "2022-12-25 09:47:13 | INFO | fairseq.trainer | begin training epoch 3\n",
      "2022-12-25 09:47:16 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "2022-12-25 09:47:18 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.36 | evt_loss 10.297 | dur_loss 2.769 | trk_loss 1.996 | ins_loss 2.38 | ppl 20.54 | evt_ppl 1258.18 | dur_ppl 6.81 | trk_ppl 3.99 | ins_ppl 5.21 | wps 24297.1 | wpb 5916.8 | bsz 1.8 | num_updates 3 | best_loss 4.339\n",
      "2022-12-25 09:47:18 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-12-25 09:47:21 | INFO | fairseq.checkpoint_utils | saved checkpoint ckpt/checkpoint3_linear_4096_chord_bpe_hardloss1_PI2.pt (epoch 3 @ 3 updates, score 4.36) (writing took 3.365952591999985 seconds)\n",
      "2022-12-25 09:47:21 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)\n",
      "2022-12-25 09:47:21 | INFO | train | epoch 003 | loss 4.67 | evt_loss 10.535 | dur_loss 3.084 | trk_loss 2.422 | ins_loss 2.639 | ppl 25.45 | evt_ppl 1483.75 | dur_ppl 8.48 | trk_ppl 5.36 | ins_ppl 6.23 | wps 2352.9 | ups 0.13 | wpb 18750 | bsz 11 | num_updates 3 | lr 1.8e-07 | gnorm 6.285 | train_wall 3 | wall 30\n",
      "2022-12-25 09:47:21 | INFO | fairseq.trainer | begin training epoch 4\n",
      "2022-12-25 09:47:25 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "2022-12-25 09:47:27 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.355 | evt_loss 10.31 | dur_loss 2.751 | trk_loss 2.005 | ins_loss 2.354 | ppl 20.46 | evt_ppl 1269.09 | dur_ppl 6.73 | trk_ppl 4.01 | ins_ppl 5.11 | wps 22233.5 | wpb 6118 | bsz 1.8 | num_updates 4 | best_loss 4.339\n",
      "2022-12-25 09:47:27 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-12-25 09:47:30 | INFO | fairseq.checkpoint_utils | saved checkpoint ckpt/checkpoint4_linear_4096_chord_bpe_hardloss1_PI2.pt (epoch 4 @ 4 updates, score 4.355) (writing took 3.506205535999925 seconds)\n",
      "2022-12-25 09:47:30 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)\n",
      "2022-12-25 09:47:30 | INFO | train | epoch 004 | loss 4.636 | evt_loss 10.514 | dur_loss 3.162 | trk_loss 2.171 | ins_loss 2.696 | ppl 24.86 | evt_ppl 1461.83 | dur_ppl 8.95 | trk_ppl 4.5 | ins_ppl 6.48 | wps 2804.9 | ups 0.11 | wpb 25467 | bsz 11 | num_updates 4 | lr 2.4e-07 | gnorm 6.25 | train_wall 4 | wall 39\n",
      "2022-12-25 09:47:30 | INFO | fairseq.trainer | begin training epoch 5\n",
      "2022-12-25 09:47:34 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "2022-12-25 09:47:35 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.395 | evt_loss 10.316 | dur_loss 2.732 | trk_loss 2.157 | ins_loss 2.376 | ppl 21.04 | evt_ppl 1275.14 | dur_ppl 6.64 | trk_ppl 4.46 | ins_ppl 5.19 | wps 14238.6 | wpb 4630.8 | bsz 1.8 | num_updates 5 | best_loss 4.339\n",
      "2022-12-25 09:47:35 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-12-25 09:47:38 | INFO | fairseq.checkpoint_utils | saved checkpoint ckpt/checkpoint5_linear_4096_chord_bpe_hardloss1_PI2.pt (epoch 5 @ 5 updates, score 4.395) (writing took 3.4751089399999273 seconds)\n",
      "2022-12-25 09:47:38 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)\n",
      "2022-12-25 09:47:38 | INFO | train | epoch 005 | loss 4.649 | evt_loss 10.492 | dur_loss 3.148 | trk_loss 2.297 | ins_loss 2.659 | ppl 25.09 | evt_ppl 1440.11 | dur_ppl 8.87 | trk_ppl 4.91 | ins_ppl 6.32 | wps 2956.4 | ups 0.12 | wpb 24352 | bsz 11 | num_updates 5 | lr 3e-07 | gnorm 5.891 | train_wall 3 | wall 47\n",
      "2022-12-25 09:47:38 | INFO | fairseq_cli.train | done training in 47.1 seconds\n"
     ]
    }
   ],
   "source": [
    "!sh train_linear_chord.sh"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import files\n",
    "files.download('ckpt/checkpoint_last_linear_4096_chord_bpe_hardloss1_PI2.pt')"
   ],
   "metadata": {
    "id": "AJX3FpEMIo5N",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "a = -1\n",
    "while True:\n",
    "  a = a * -1"
   ],
   "metadata": {
    "id": "DrJXA510I1RY",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pPJImSuCjVFq",
    "outputId": "9f87ee57-e727-4c99-f699-8f7666e38d45",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DGH_Q-tYUiGB",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model preparation"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pwd"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8HXD76soIqiR",
    "outputId": "9ce1a982-6763-404d-a4a4-55bcac937484",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "%cd ../"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Me9sq_WWqbDR",
    "outputId": "57fdc41b-5f8d-4eae-f899-a4a98706492d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "owMvhFUWUgcU",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "MAX_POS_LEN = 4096\n",
    "PI_LEVEL = 2\n",
    "IGNORE_META_LOSS = 1\n",
    "RATIO = 4\n",
    "BPE = \"_bpe\" # or \"\"\n",
    "\n",
    "DATA_BIN=f\"linear_{MAX_POS_LEN}_chord{BPE}_hardloss{IGNORE_META_LOSS}\"\n",
    "CHECKPOINT_SUFFIX=f\"{DATA_BIN}_PI{PI_LEVEL}\"\n",
    "DATA_BIN_DIR=f\"SymphonyNet/data/model_spec/{DATA_BIN}/bin/\"\n",
    "DATA_VOC_DIR=f\"SymphonyNet/data/model_spec/{DATA_BIN}/vocabs/\"\n",
    "from SymphonyNet.src.fairseq.gen_utils import process_prime_midi, gen_one, get_trk_ins_map, get_note_seq, note_seq_to_midi_file, music_dict\n",
    "music_dict.load_vocabs_bpe(DATA_VOC_DIR, 'SymphonyNet/data/bpe_res/' if BPE == '_bpe' else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g-rHo-owUlwo",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Initialize the model and load pretrained parameters. (You should first save the provided [ckpt file](https://drive.google.com/file/d/1xpkj_qN4MdLRkBdCXmfGjuWWjnTN1Og0/view) into your google drive.)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pwd"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D0-d1clftAge",
    "outputId": "55682517-c8d9-4c26-a627-a2fde5fba0b5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2EQMHbzvUkqj",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "outputId": "70b8ba16-3aab-45ef-81f6-b49178e59d62",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-2-8742f665af94>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mfairseq\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodels\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mFairseqLanguageModel\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mgoogle\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolab\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mdrive\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mdrive\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmount\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'/content/drive'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m custom_lm = FairseqLanguageModel.from_pretrained('.', \n\u001B[1;32m      5\u001B[0m     \u001B[0mcheckpoint_file\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34mf'SymphonyNet/ckpt/checkpoint_last_linear_4096_chord_bpe_hardloss1_PI2.pt'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'fairseq'",
      "",
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n"
     ],
     "errorDetails": {
      "actions": [
       {
        "action": "open_url",
        "actionText": "Open Examples",
        "url": "/notebooks/snippets/importing_libraries.ipynb"
       }
      ]
     }
    }
   ],
   "source": [
    "from fairseq.models import FairseqLanguageModel\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "custom_lm = FairseqLanguageModel.from_pretrained('.', \n",
    "    checkpoint_file=f'SymphonyNet/ckpt/checkpoint_last_linear_4096_chord_bpe_hardloss1_PI2.pt', \n",
    "    data_name_or_path=DATA_BIN_DIR, \n",
    "    user_dir=\"SymphonyNet/src/fairseq/linear_transformer_inference\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pwd"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ESpj9cYIVkQB",
    "outputId": "c00d324c-249c-4cd8-affe-c2d8b3477678",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "orig_lm = FairseqLanguageModel.from_pretrained('.', \n",
    "    checkpoint_file=f'drive/MyDrive/orig_model.pt', \n",
    "    data_name_or_path=DATA_BIN_DIR, \n",
    "    user_dir=\"SymphonyNet/src/fairseq/linear_transformer_inference\")"
   ],
   "metadata": {
    "id": "bhaVs-rCgOHR",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "outputId": "de6e9ae1-84a4-425f-9f00-6f4eead538f1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-1-1580aa45a60d>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m orig_lm = FairseqLanguageModel.from_pretrained('.', \n\u001B[0m\u001B[1;32m      2\u001B[0m     \u001B[0mcheckpoint_file\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34mf'drive/MyDrive/orig_model.pt'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m     \u001B[0mdata_name_or_path\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mDATA_BIN_DIR\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m     user_dir=\"SymphonyNet/src/fairseq/linear_transformer_inference\")\n",
      "\u001B[0;31mNameError\u001B[0m: name 'FairseqLanguageModel' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "for embedding_layers in ['wEvte', 'wTrke','wDure','wRpe','wMpe']:\n",
    "\n",
    "  a = getattr(orig_lm.models[0].decoder, embedding_layers)\n",
    "  setattr(custom_lm.models[0].decoder, embedding_layers, a) \n"
   ],
   "metadata": {
    "id": "8_BGxecFARwL",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xPOOo9hXUogE",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "m = custom_lm.models[0]\n",
    "m.cuda()\n",
    "m.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wwywwsq_UquV",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Prepare prime MIDI"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pwd"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6p-YyjOtt1Uj",
    "outputId": "1abbc1b0-ffd4-4467-a687-98fe05855daa",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "%cd SymphonyNet"
   ],
   "metadata": {
    "id": "GtzK2LjNuDL-",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e96682f2-133c-47dc-9ba2-73491a6ec887",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/SymphonyNet\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ILD3_qlnUplc",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "outputId": "0d06eace-a55d-43d6-9f97-f7e672668525",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-45-b484b1c306ba>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0mmax_measure_cnt\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m5\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mmax_chord_measure_cnt\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m \u001B[0mprime\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mins_label\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mprocess_prime_midi\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmidi_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmax_measure_cnt\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmax_chord_measure_cnt\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/content/SymphonyNet/src/fairseq/gen_utils.py\u001B[0m in \u001B[0;36mprocess_prime_midi\u001B[0;34m(prime_midi_path, max_measures, max_chord_measures, perm_inv, ratio, sample_len_max)\u001B[0m\n\u001B[1;32m     77\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     78\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 79\u001B[0;31m     \u001B[0mmeasures\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mprocess_single_piece\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtoks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmusic_dict\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstr2int\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mratio\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msample_len_max\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     80\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     81\u001B[0m     \u001B[0mprime_nums\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mEOS\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mratio\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/content/SymphonyNet/src/fairseq/make_data.py\u001B[0m in \u001B[0;36mprocess_single_piece\u001B[0;34m(bundle_input, ratio, sample_len_max)\u001B[0m\n\u001B[1;32m     71\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;31m# on token\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     72\u001B[0m             \u001B[0;32mpass\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 73\u001B[0;31m         \u001B[0mcur_mea\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mstr2int\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mstr_toks\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0mratio\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mrel_pos\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlower\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m'p'\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mrel_pos\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     74\u001B[0m     \u001B[0;31m#TODO: how to design rel_pos and measure pos?\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     75\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcur_mea\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/content/SymphonyNet/src/fairseq/make_data.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     71\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;31m# on token\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     72\u001B[0m             \u001B[0;32mpass\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 73\u001B[0;31m         \u001B[0mcur_mea\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mstr2int\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mstr_toks\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0mratio\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mrel_pos\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlower\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m'p'\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mrel_pos\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     74\u001B[0m     \u001B[0;31m#TODO: how to design rel_pos and measure pos?\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     75\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcur_mea\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'X9'"
     ]
    }
   ],
   "source": [
    "midi_name = 'test.mid'\n",
    "max_measure_cnt = 5\n",
    "max_chord_measure_cnt = 0\n",
    "prime, ins_label = process_prime_midi(midi_name, max_measure_cnt, max_chord_measure_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LL_T41CFUunt",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "a = 1\n",
    "while True:\n",
    "  a = a * -1"
   ],
   "metadata": {
    "id": "x-zX6o6V96S5",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "outputId": "a6f83548-dfac-49a4-8b72-53484b4e4a9a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-16-538c7138fadb>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0ma\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;32mwhile\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m   \u001B[0ma\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0ma\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nG4COxgxUtLm",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 727
    },
    "outputId": "246e6b1e-f3db-4a20-8d0b-fbc15e304102",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 2/3720 [00:00<01:06, 55.84it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Invalid generation: there must be a <bom> before a chord 16\n",
      "Invalid generation: there must be a <bom> before a chord 16\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 7/3720 [00:00<00:49, 74.90it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Invalid generation: there must be a <bom> before a chord 16\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 3/3720 [00:00<01:00, 61.48it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Invalid generation: there must be a <bom> before a chord 16\n",
      "Invalid generation: there must be a <bom> before a chord 16\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 5/3720 [00:00<00:54, 68.43it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Invalid generation: there must be a <bom> before a chord 16\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 4/3720 [00:00<00:56, 65.28it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Invalid generation: there must be a <bom> before a chord 16\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 8/3720 [00:00<00:48, 77.28it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Invalid generation: there must be a <bom> before a chord 16\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 3/3720 [00:00<01:04, 57.56it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Invalid generation: there must be a <bom> before a chord 16\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 1/3720 [00:00<01:38, 37.93it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Invalid generation: there must be a <bom> before a chord 16\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 3/3720 [00:00<00:59, 61.98it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Invalid generation: there must be a <bom> before a chord 16\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-26-6fbfe4e438e4>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;32mwhile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m   \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m     \u001B[0mgenerated\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mins_logits\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgen_one\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mm\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mprime\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mMIN_LEN\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m1024\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      5\u001B[0m     \u001B[0;32mbreak\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m   \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/content/SymphonyNet/src/fairseq/gen_utils.py\u001B[0m in \u001B[0;36mgen_one\u001B[0;34m(model, prime_nums, MAX_LEN, MIN_LEN)\u001B[0m\n\u001B[1;32m    221\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mitem\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnext_item\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprime\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mprime\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    222\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 223\u001B[0;31m             \u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0md\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mt\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mins\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmemo\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_next\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mitem\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmemo\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhas_prime\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    224\u001B[0m             \u001B[0mcur_rel_pos\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcur_mea\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcalc_pos\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnext_item\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcur_rel_pos\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcur_mea\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    225\u001B[0m             \u001B[0mins_list\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mins\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/content/SymphonyNet/src/fairseq/gen_utils.py\u001B[0m in \u001B[0;36mget_next\u001B[0;34m(model, p, memory, has_prime)\u001B[0m\n\u001B[1;32m    151\u001B[0m     \u001B[0mpr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrom_numpy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mp\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    152\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 153\u001B[0;31m     \u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0md\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mt\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mins\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmemory\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msrc_tokens\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mpr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msrc_lengths\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmemory\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    154\u001B[0m     \u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0md\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mins\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0md\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mins\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    155\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mhas_prime\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    725\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    726\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 727\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    728\u001B[0m         for hook in itertools.chain(\n\u001B[1;32m    729\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.8/dist-packages/fairseq/models/fairseq_model.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, src_tokens, **kwargs)\u001B[0m\n\u001B[1;32m    479\u001B[0m                 \u001B[0;34m-\u001B[0m \u001B[0ma\u001B[0m \u001B[0mdictionary\u001B[0m \u001B[0;32mwith\u001B[0m \u001B[0many\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0mspecific\u001B[0m \u001B[0moutputs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    480\u001B[0m         \"\"\"\n\u001B[0;32m--> 481\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdecoder\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msrc_tokens\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    482\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    483\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward_decoder\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mprev_output_tokens\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    725\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    726\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 727\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    728\u001B[0m         for hook in itertools.chain(\n\u001B[1;32m    729\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/content/SymphonyNet/src/fairseq/linear_transformer_inference/linear_transformer_multi.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x, src_lengths)\u001B[0m\n\u001B[1;32m    251\u001B[0m         \u001B[0msrc_lengths\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    252\u001B[0m     ):\n\u001B[0;32m--> 253\u001B[0;31m         \u001B[0mfeatures\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmemory\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mextract_features\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msrc_lengths\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    254\u001B[0m         \u001B[0mevt_logits\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mproj_evt\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfeatures\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    255\u001B[0m         \u001B[0mdur_logits\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mproj_dur\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfeatures\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/content/SymphonyNet/src/fairseq/linear_transformer_inference/linear_transformer_multi.py\u001B[0m in \u001B[0;36mextract_features\u001B[0;34m(self, x, src_lengths)\u001B[0m\n\u001B[1;32m    283\u001B[0m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdrop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mevt_emb\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0mdur_emb\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0mtrk_emb\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0mpos_emb\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    284\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 285\u001B[0;31m         \u001B[0moutputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmemory\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msqueeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msrc_lengths\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    286\u001B[0m         \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mln_f\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    287\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    725\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    726\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 727\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    728\u001B[0m         for hook in itertools.chain(\n\u001B[1;32m    729\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.8/dist-packages/fast_transformers/recurrent/transformers.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x, state, memory)\u001B[0m\n\u001B[1;32m    130\u001B[0m         \u001B[0;31m# Apply all the transformers\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    131\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlayer\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayers\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 132\u001B[0;31m             \u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0ms\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlayer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstate\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    133\u001B[0m             \u001B[0mstate\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0ms\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    134\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    725\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    726\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 727\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    728\u001B[0m         for hook in itertools.chain(\n\u001B[1;32m    729\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.8/dist-packages/fast_transformers/recurrent/transformers.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x, state, memory)\u001B[0m\n\u001B[1;32m     76\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     77\u001B[0m         \u001B[0;31m# Run the self attention and add it to the input\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 78\u001B[0;31m         \u001B[0mx2\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstate\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mattention\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstate\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     79\u001B[0m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mx\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdropout\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     80\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    725\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    726\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 727\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    728\u001B[0m         for hook in itertools.chain(\n\u001B[1;32m    729\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.8/dist-packages/fast_transformers/recurrent/attention/self_attention/attention_layer.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, query, key, value, state, memory)\u001B[0m\n\u001B[1;32m     78\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     79\u001B[0m         \u001B[0;31m# Project the queries/keys/values\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 80\u001B[0;31m         \u001B[0mquery\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mquery_projection\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mquery\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     81\u001B[0m         \u001B[0mkey\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkey_projection\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     82\u001B[0m         \u001B[0mvalue\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalue_projection\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    725\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    726\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 727\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    728\u001B[0m         for hook in itertools.chain(\n\u001B[1;32m    729\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m     91\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     92\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 93\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlinear\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     94\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     95\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mextra_repr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\u001B[0m in \u001B[0;36mlinear\u001B[0;34m(input, weight, bias)\u001B[0m\n\u001B[1;32m   1688\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdim\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m2\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mbias\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1689\u001B[0m         \u001B[0;31m# fused op is marginally faster\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1690\u001B[0;31m         \u001B[0mret\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maddmm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbias\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mt\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1691\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1692\u001B[0m         \u001B[0moutput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmatmul\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mt\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "while(True):\n",
    "  try:\n",
    "    generated, ins_logits = gen_one(m, prime, MIN_LEN = 1024)\n",
    "    break\n",
    "  except Exception as e:\n",
    "    print(e)\n",
    "    continue\n",
    "trk_ins_map = get_trk_ins_map(generated, ins_logits)\n",
    "note_seq = get_note_seq(generated, trk_ins_map)\n",
    "timestamp = time.strftime(\"%m-%d_%H-%M-%S\", time.localtime()) \n",
    "output_name = f'output_prime{max_measure_cnt}_chord{max_chord_measure_cnt}_{timestamp}.mid'\n",
    "note_seq_to_midi_file(note_seq, output_name)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import files\n",
    "files.download(output_name)"
   ],
   "metadata": {
    "id": "i3vwcPrG-gct",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P5fNk1FPU1Uo",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Audio Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jTsalwBrUzoz",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "88bce5ef-1901-40fa-9810-a0ddba546aec",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following package was automatically installed and is no longer required:\n",
      "  libnvidia-common-460\n",
      "Use 'sudo apt autoremove' to remove it.\n",
      "The following additional packages will be installed:\n",
      "  fluid-soundfont-gm libfluidsynth1 libqt5x11extras5 qsynth\n",
      "Suggested packages:\n",
      "  fluid-soundfont-gs timidity jackd\n",
      "The following NEW packages will be installed:\n",
      "  fluid-soundfont-gm fluidsynth libfluidsynth1 libqt5x11extras5 qsynth\n",
      "0 upgraded, 5 newly installed, 0 to remove and 20 not upgraded.\n",
      "Need to get 120 MB of archives.\n",
      "After this operation, 150 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fluid-soundfont-gm all 3.1-5.1 [119 MB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libfluidsynth1 amd64 1.1.9-1 [137 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fluidsynth amd64 1.1.9-1 [20.7 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libqt5x11extras5 amd64 5.9.5-0ubuntu1 [8,596 B]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu bionic/universe amd64 qsynth amd64 0.5.0-2 [191 kB]\n",
      "Fetched 120 MB in 6s (18.7 MB/s)\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 5.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "dpkg-preconfigure: unable to re-open stdin: \n",
      "Selecting previously unselected package fluid-soundfont-gm.\n",
      "(Reading database ... 124016 files and directories currently installed.)\n",
      "Preparing to unpack .../fluid-soundfont-gm_3.1-5.1_all.deb ...\n",
      "Unpacking fluid-soundfont-gm (3.1-5.1) ...\n",
      "Selecting previously unselected package libfluidsynth1:amd64.\n",
      "Preparing to unpack .../libfluidsynth1_1.1.9-1_amd64.deb ...\n",
      "Unpacking libfluidsynth1:amd64 (1.1.9-1) ...\n",
      "Selecting previously unselected package fluidsynth.\n",
      "Preparing to unpack .../fluidsynth_1.1.9-1_amd64.deb ...\n",
      "Unpacking fluidsynth (1.1.9-1) ...\n",
      "Selecting previously unselected package libqt5x11extras5:amd64.\n",
      "Preparing to unpack .../libqt5x11extras5_5.9.5-0ubuntu1_amd64.deb ...\n",
      "Unpacking libqt5x11extras5:amd64 (5.9.5-0ubuntu1) ...\n",
      "Selecting previously unselected package qsynth.\n",
      "Preparing to unpack .../qsynth_0.5.0-2_amd64.deb ...\n",
      "Unpacking qsynth (0.5.0-2) ...\n",
      "Setting up libqt5x11extras5:amd64 (5.9.5-0ubuntu1) ...\n",
      "Setting up fluid-soundfont-gm (3.1-5.1) ...\n",
      "Setting up libfluidsynth1:amd64 (1.1.9-1) ...\n",
      "Setting up fluidsynth (1.1.9-1) ...\n",
      "Setting up qsynth (0.5.0-2) ...\n",
      "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
      "Processing triggers for mime-support (3.60ubuntu1) ...\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1.6) ...\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
     ]
    }
   ],
   "source": [
    "!sudo apt install -y fluidsynth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CtUrwTzsU4Xo",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "25fbf7bf-da15-4f28-81c1-18bee00f2fe6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting pyfluidsynth\n",
      "  Downloading pyFluidSynth-1.3.1-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from pyfluidsynth) (1.21.6)\n",
      "Installing collected packages: pyfluidsynth\n",
      "Successfully installed pyfluidsynth-1.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pyfluidsynth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yu9ZI0mZU7PQ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "55372f23-8019-4f60-97b0-78b60f4f8182",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting pretty_midi\n",
      "  Downloading pretty_midi-0.2.9.tar.gz (5.6 MB)\n",
      "\u001B[K     |████████████████████████████████| 5.6 MB 4.5 MB/s \n",
      "\u001B[?25hRequirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from pretty_midi) (1.21.6)\n",
      "Requirement already satisfied: mido>=1.1.16 in /usr/local/lib/python3.8/dist-packages (from pretty_midi) (1.2.10)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from pretty_midi) (1.15.0)\n",
      "Building wheels for collected packages: pretty-midi\n",
      "  Building wheel for pretty-midi (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for pretty-midi: filename=pretty_midi-0.2.9-py3-none-any.whl size=5591954 sha256=54b74862148297b541d8e584df1dc13ba6becef1c3bf30df7a5dfd4984c68a27\n",
      "  Stored in directory: /root/.cache/pip/wheels/2a/5a/e3/30eeb9a99350f3f7e21258fcb132743eef1a4f49b3505e76b6\n",
      "Successfully built pretty-midi\n",
      "Installing collected packages: pretty-midi\n",
      "Successfully installed pretty-midi-0.2.9\n"
     ]
    }
   ],
   "source": [
    "!pip install pretty_midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oHVCzTNUU8PG",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import fluidsynth\n",
    "import pretty_midi\n",
    "from IPython import display\n",
    "_SAMPLING_RATE = 16000\n",
    "def display_audio(pm: pretty_midi.PrettyMIDI, seconds=300):\n",
    "  waveform = pm.fluidsynth(fs=_SAMPLING_RATE)\n",
    "  # Take a sample of the generated waveform to mitigate kernel resets\n",
    "  waveform_short = waveform[:seconds*_SAMPLING_RATE]\n",
    "  return display.Audio(waveform_short, rate=_SAMPLING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LVERsgwhZAi-",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 189
    },
    "outputId": "c177f9d5-b3d2-4e23-fc7b-0888c9ae9715",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-1-7e514ef38031>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mpm\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpretty_midi\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mPrettyMIDI\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutput_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mdisplay_audio\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpm\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'pretty_midi' is not defined"
     ]
    }
   ],
   "source": [
    "pm = pretty_midi.PrettyMIDI(output_name)\n",
    "display_audio(pm)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "gpuClass": "standard",
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}